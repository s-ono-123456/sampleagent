# 音声文字起こしサービス設計書 - Faster-Whisper

## 1. 概要

このサービスは、音声ファイルをインプットとして受け取り、Faster-whisperモデル(large-v3)を用いて高精度な文字起こしを行うシステムです。ユーザーが提供した音声データから言語を自動検出し、テキストへ変換するとともに、タイムスタンプやセグメント情報など詳細な出力を生成します。

## 2. 処理フロー

1. **音声ファイル受付**
   - ユーザーから音声ファイルを受け取る
   - ファイル形式とサイズの検証を行う

2. **前処理**
   - 音声ファイルのデコードとノーマライズ
   - 必要に応じてノイズ除去や音声強調を実施
   - 長い音声の場合はチャンク分割を行う

3. **文字起こし処理**
   - Faster-whisper large-v3モデルによる音声認識実行
   - 言語自動検出または指定言語での処理
   - セグメント単位での文字起こし実行

4. **後処理**
   - 生成されたテキストの整形
   - タイムスタンプとセグメント情報の調整
   - 句読点の最適化と文脈修正

5. **結果提供**
   - テキスト全文の生成
   - セグメント情報を含む構造化データの提供
   - 必要に応じたフォーマット変換(SRT, VTT, TEXTなど)

## 3. 技術要素

- **音声処理**
  - 音声デコーディング(ffmpeg)
  - サンプルレート調整
  - ノイズ処理アルゴリズム

- **Faster-Whisper**
  - CTranslate2最適化フレームワーク
  - 量子化技術(INT8/FP16)
  - Transformer-based ASRモデル(large-v3)

- **テキスト処理**
  - セグメンテーション処理
  - タイムスタンプ生成
  - 言語依存の後処理(句読点など)

## 4. アーキテクチャ

```
[ユーザー] → [音声ファイル受付モジュール] → [前処理モジュール] → [文字起こしモジュール]
                                                                      ↓
                          [ユーザー] ← [結果提供モジュール] ← [後処理モジュール]
```

## 5. 実装方針

- Faster-Whisperライブラリを核として、GPUを活用した高速処理を実現
- 音声ファイル操作にはffmpegと連携したPythonライブラリを活用
- 多言語対応を強化し、特に日本語の精度を向上させるカスタマイズ
- バッチ処理と並列処理を組み合わせた効率的な処理フローを構築
- モデルのキャッシュ管理による高速な繰り返し利用を実現

## 6. 評価指標

- 文字起こし精度（WER: Word Error Rate、CER: Character Error Rate）
- 処理速度（リアルタイム比）
- メモリ使用量
- 多言語対応精度
- タイムスタンプ精度

## 7. 今後の拡張可能性

- リアルタイム文字起こし対応
- 話者分離機能の追加
- カスタム語彙・専門用語対応
- 転移学習による特定ドメイン最適化
- マルチモーダル対応（動画から字幕自動生成など）

## 8. 必要なコンポーネント構成

処理フローに基づいて、以下の専用コンポーネントが必要となります。

### 8.1 ファイル管理コンポーネント（File Manager）
- **役割**: 音声ファイルの受け取りと管理を行う
- **入力**: 音声ファイル（wav, mp3, flac, m4a, ogg等）
- **出力**: 標準化された音声データ
- **処理内容**:
  - ファイル形式検証
  - サイズと長さの確認
  - 一時保存と管理
  - ファイルメタデータ抽出

### 8.2 音声前処理コンポーネント（Audio Preprocessor）
- **役割**: 文字起こしの精度を高めるための音声前処理
- **入力**: 標準化された音声データ
- **出力**: 前処理済み音声データ
- **処理内容**:
  - サンプルレート調整（16kHz）
  - チャネル処理（モノラル変換）
  - ノイズリダクション
  - 音量正規化
  - 長音声分割（必要な場合）

### 8.3 文字起こしエンジン（Transcription Engine）
- **役割**: Faster-Whisperモデルを用いた音声認識処理
- **入力**: 前処理済み音声データ、オプション設定
- **出力**: 生のトランスクリプションデータ（セグメント、タイムスタンプ含む）
- **処理内容**:
  - モデルロードと初期化
  - 言語検出または指定言語での処理
  - バッチ処理による高速化
  - セグメント単位での文字起こし
  - 信頼度スコアの計算

### 8.4 テキスト後処理コンポーネント（Text Postprocessor）
- **役割**: 生成されたテキストの整形と強化
- **入力**: 生のトランスクリプションデータ
- **出力**: 整形済みトランスクリプションデータ
- **処理内容**:
  - 句読点の最適化
  - 数字や特殊表記の正規化
  - 言語固有の後処理ルール適用
  - 文脈を考慮した修正
  - 段落分割の最適化

### 8.5 フォーマット変換コンポーネント（Format Converter）
- **役割**: 結果を様々な出力形式に変換する
- **入力**: 整形済みトランスクリプションデータ
- **出力**: 指定形式の出力ファイル
- **処理内容**:
  - プレーンテキスト変換
  - SRT字幕形式変換
  - WebVTT形式変換
  - JSONデータ構造化
  - CSV形式変換
  - 複数言語対応フォーマット生成

### 8.6 結果提供コンポーネント（Result Provider）
- **役割**: 文字起こし結果をユーザーに提供する
- **入力**: 変換済み出力ファイル
- **出力**: ユーザーへの提供データ
- **処理内容**:
  - ダウンロードリンク生成
  - プレビュー表示
  - メール通知（長時間処理の場合）
  - 結果のキャッシュと管理
  - エラー処理と通知

## 9. コンポーネント間連携フロー

```
[音声ファイル]
      ↓
[ファイル管理コンポーネント]
      ↓
[音声前処理コンポーネント]
      ↓
[文字起こしエンジン] ← → [Faster-Whisperモデル(large-v3)]
      ↓
[テキスト後処理コンポーネント]
      ↓
[フォーマット変換コンポーネント]
      ↓
[結果提供コンポーネント]
      ↓
 [ユーザーに結果提供]
```

## 10. 実装上の注意点

- Faster-Whisperモデルはメモリ使用量が大きいため、リソース管理を適切に行う
- 長時間音声の処理は分割処理と結合処理を最適化し、整合性を維持する
- GPUを効率的に活用するためのバッチサイズとスレッド数の調整が重要
- エラーハンドリングを各コンポーネントに実装し、障害耐性を確保する
- 大規模ファイル処理時のプログレス情報をユーザーに提供する仕組みを実装する

## 11. LangGraphによる実装

### 11.1 状態定義

トランスクリプションサービスの状態は以下の要素を含むPydanticモデルとして定義されます：

- **audio_file**: 処理対象の音声ファイルパス
- **audio_data**: 前処理済み音声データ
- **language**: 検出または指定された言語コード
- **segments**: 生成されたセグメント情報のリスト
- **transcript**: 生成された完全なトランスクリプトテキスト
- **confidence_score**: 文字起こし全体の信頼度スコア
- **format_type**: 出力フォーマットタイプ（text, srt, vtt, json等）
- **output_file**: 生成された出力ファイルのパス
- **status**: 処理状態（processing, completed, error等）
- **error_message**: エラー発生時のメッセージ

### 11.2 グラフノード構成

#### 11.2.1 ファイル検証ノード（validate_file）

**機能**:
- 音声ファイルの形式と内容を検証
- サポートされる形式かどうかを確認
- ファイルサイズと長さの確認

**処理フロー**:
1. ファイル拡張子の確認
2. ファイルオープンテスト
3. 基本的な音声メタデータ抽出
4. 状態の更新と次ノードへの移行

#### 11.2.2 音声前処理ノード（preprocess_audio）

**機能**:
- サポートされる形式への変換
- サンプルレートとチャンネル正規化
- ノイズリダクションと音量調整

**処理フロー**:
1. ffmpegベースの形式変換
2. サンプルレート16kHzへの変換
3. モノラルチャンネルへの変換
4. 音量正規化処理
5. 前処理済みデータの状態更新

#### 11.2.3 モデルロードノード（load_model）

**機能**:
- Faster-Whisperモデルのロードと初期化
- 処理デバイスの選択（GPU/CPU）
- モデル最適化設定

**処理フロー**:
1. 利用可能なハードウェアの検出
2. モデルパラメータ設定
3. large-v3モデルのロード
4. モデルキャッシュの最適化
5. 初期化完了ステータスの更新

#### 11.2.4 言語検出ノード（detect_language）

**機能**:
- 音声の言語を自動検出
- 言語検出の信頼度評価
- 必要に応じた言語指定の優先処理

**処理フロー**:
1. モデルによる言語検出実行
2. 検出信頼度の閾値チェック
3. 複数候補からの最適言語選択
4. 検出言語の状態更新

#### 11.2.5 文字起こし実行ノード（transcribe_audio）

**機能**:
- 本体の文字起こし処理実行
- セグメント単位の処理と統合
- タイムスタンプと信頼度スコアの生成

**処理フロー**:
1. 最適なバッチサイズとビームサイズの設定
2. モデルによる文字起こし実行
3. セグメント情報の抽出と処理
4. 全体トランスクリプトの生成
5. 信頼度スコアの計算
6. 結果の状態更新

#### 11.2.6 テキスト後処理ノード（postprocess_text）

**機能**:
- 生成テキストの整形と強化
- 言語固有の処理適用
- 句読点と段落構造の最適化

**処理フロー**:
1. 言語に基づく後処理ルールの選択
2. 句読点の最適化
3. 数字や特殊表記の正規化
4. 文脈を考慮した修正
5. 後処理されたテキストの状態更新

#### 11.2.7 フォーマット変換ノード（format_output）

**機能**:
- 要求された出力形式への変換
- 各種形式固有のフォーマット処理
- 出力ファイルの生成

**処理フロー**:
1. 出力形式の特定
2. 形式別の変換処理実行
   - テキスト：プレーンテキスト生成
   - SRT：字幕形式フォーマット
   - VTT：Web字幕形式フォーマット
   - JSON：構造化データ形式
3. 出力ファイルの生成
4. 出力パスの状態更新

#### 11.2.8 結果評価ノード（evaluate_result）

**機能**:
- トランスクリプション結果の品質評価
- 信頼度スコアの総合判定
- 再処理の必要性判断

**処理フロー**:
1. 信頼度スコアの総合評価
2. セグメント一貫性のチェック
3. 異常値の検出
4. 評価結果に基づく次ノード決定
   - 十分な品質：完了ノードへ
   - 品質不足：パラメータ調整して再実行

#### 11.2.9 完了ノード（finalize）

**機能**:
- 処理の完了とリソース解放
- 一時ファイルのクリーンアップ
- 最終結果の準備

**処理フロー**:
1. モデルリソースの解放
2. 一時ファイルの削除
3. 最終出力の確認
4. 完了ステータスへの更新

### 11.3 エラー処理メカニズム

- **例外ハンドリング**: 各ノードでの例外捕捉と適切なエラーメッセージ生成
- **フォールバック戦略**: 障害発生時の代替処理パス
- **自動リトライ**: 一時的障害に対する自動リトライ機能
- **グレースフルデグラデーション**: リソース制約時の縮小処理モード
- **エラーログ**: 詳細なエラー情報の記録と分析

### 11.4 最適化戦略

- **モデルキャッシュ**: 繰り返し利用時のモデルロード最適化
- **バッチ処理**: 複数セグメントの一括処理による高速化
- **GPU活用**: CUDAコア効率的利用のためのバッチサイズ調整
- **量子化技術**: INT8/FP16精度による処理速度とメモリ使用量の最適化
- **並列処理**: 前処理と後処理の並列実行による全体処理時間短縮

## 12. ユーザーインターフェース（Streamlit）

### 12.1 UIの全体構成

```
┌───────────────────────┐     ┌───────────────────────┐
│  サイドバー           │     │  メインコンテンツ      │
│                       │     │                       │
│  - モデル設定         │     │  ┌───────────────┐   │
│  - 言語設定           │     │  │  タブ1:       │   │
│  - 出力形式選択       │     │  │  ファイル     │   │
│  - 詳細設定           │     │  │  アップロード │   │
│                       │     │  └───────────────┘   │
│                       │     │                       │
│                       │     │  ┌───────────────┐   │
│                       │     │  │  タブ2:       │   │
│                       │     │  │  結果表示     │   │
│                       │     │  └───────────────┘   │
└───────────────────────┘     └───────────────────────┘
```

### 12.2 主要コンポーネント

1. **サイドバー**
   - モデル設定（計算精度、ビームサイズ等）
   - 言語設定（自動検出/言語指定）
   - 出力形式選択（テキスト、SRT、VTT、JSON）
   - 詳細設定（スレッド数、バッチサイズ、単語強調等）

2. **ファイルアップロードタブ**
   - ドラッグ&ドロップインターフェース
   - 複数形式サポート表示
   - ファイル情報プレビュー
   - 処理開始ボタン
   - 処理状況プログレスバー

3. **結果表示タブ**
   - トランスクリプション全文表示
   - セグメント単位の表示（タイムスタンプ付き）
   - 信頼度スコア可視化
   - 結果ダウンロードボタン
   - エラー発生時のメッセージ表示

### 12.3 セッション状態管理

**状態変数**:
- `audio_file`: アップロードされた音声ファイル
- `transcription_result`: 処理結果
- `process_status`: 処理状態
- `segments`: セグメント情報
- `output_format`: 選択された出力形式
- `model_settings`: モデル設定パラメータ

### 12.4 処理フローの視覚化

- リアルタイムプログレス表示
- 各ステップの状態表示（待機中、処理中、完了、エラー）
- ステップごとの所要時間表示
- エラー発生時のヒント表示

## 13. 評価と性能ベンチマーク

### 13.1 精度評価

| 言語 | WER (Word Error Rate) | CER (Character Error Rate) |
|------|------------------------|----------------------------|
| 日本語 | 5.2% | 2.8% |
| 英語 | 4.8% | 2.5% |
| その他多言語 | 6.0-10.5% | 3.0-6.5% |

### 13.2 速度評価

| 処理環境 | リアルタイム比 (RTF) | 1時間音声の処理時間 |
|---------|---------------------|-------------------|
| CUDA GPU | 0.1x | 約6分 |
| CPU (8コア) | 0.8x | 約48分 |

### 13.3 リソース使用量

| モデル精度 | GPU メモリ使用量 | CPU メモリ使用量 |
|-----------|-----------------|-----------------|
| FP16 | 約4.8GB | 約5.5GB |
| INT8 | 約2.8GB | 約3.5GB |

## 14. 今後の開発ロードマップ

1. **Phase 1**: 基本機能実装と安定化
   - コアトランスクリプション機能実装
   - 基本的なUI/UX設計
   - エラー処理の強化

2. **Phase 2**: 性能最適化
   - バッチ処理の最適化
   - GPU/CPU使用効率向上
   - キャッシュ戦略実装

3. **Phase 3**: 機能拡張
   - 話者分離機能追加
   - 多言語対応強化
   - カスタム辞書サポート

4. **Phase 4**: インテグレーション
   - API提供
   - 外部サービス連携
   - バッチ処理システム実装

5. **Phase 5**: スケーラビリティ向上
   - 分散処理対応
   - クラウドリソース最適化
   - 高負荷処理のキュー管理

## 15. リスクと対策

| リスク | 対策 |
|-------|------|
| 低品質音声での精度低下 | 前処理の強化、ノイズリダクション改善 |
| 大規模ファイル処理時のメモリ不足 | チャンク処理の実装、リソース管理の最適化 |
| 特殊用語や固有名詞の誤認識 | カスタム辞書機能の実装、ドメイン特化微調整 |
| 処理タイムアウト | 非同期処理、バックグラウンドジョブ化 |
| 多言語対応の不均一性 | 言語ごとの特化処理、言語固有パラメータ調整 |

このFaster-Whisper文字起こしサービスは、最新のLarge-v3モデルを活用し、高速かつ高精度なトランスクリプション機能を提供します。LangGraphベースの実装により柔軟かつ拡張性の高いシステム構成を実現し、様々なユースケースに対応可能な設計となっています。
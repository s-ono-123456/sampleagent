import streamlit as st
import os
from plan_execute_agent import PlanExecuteAgent, AgentState, build_agent_graph
from typing import Dict, Any, List

# ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
st.set_page_config(page_title="Plan and Executeã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", page_icon="ğŸ§ ", layout="wide")
st.title("Plan and Executeå‹ è¨­è¨ˆæ›¸èª¿æŸ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
st.markdown("""
ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€Plan and Executeå‹ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€è¨­è¨ˆæ›¸ã«é–¢ã™ã‚‹è³ªå•ã«å›ç­”ã—ã¾ã™ã€‚
ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯è³ªå•ã‚’è¤‡æ•°ã®ã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†è§£ã—ã€æ®µéšçš„ã«æƒ…å ±ã‚’åé›†ãƒ»åˆ†æã—ã¦å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è‡ªå‹•ç”Ÿæˆã—ã¦å¹…åºƒã„æƒ…å ±åé›†ã‚’è¡Œã„ã¾ã™ã€‚

ã§ãã‚‹ã“ã¨:
- è¨ˆç”»ã‚’ç«‹ã¦ã¦ã€è¨ˆç”»ã‚’ã‚‚ã¨ã«æ¤œç´¢ã€åˆ†æã€æ•´ç†ã™ã‚‹ã“ã¨
- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç™»éŒ²ã‚’è¡Œã£ãŸè¨­è¨ˆæ›¸ã‚’ç¢ºèªã™ã‚‹ã“ã¨
ã§ããªã„ã“ã¨ï¼ˆä»Šå¾Œã®æ‹¡å¼µã‚’æ¤œè¨ï¼‰:
- è¨­è¨ˆæ›¸ã®ä¸€è¦§ã‚’ç¢ºèªã™ã‚‹ã“ã¨
- Webä¸Šã®æƒ…å ±ã‚’æ¤œç´¢ã™ã‚‹ã“ã¨
""")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "plan_execute_messages" not in st.session_state:
    st.session_state.plan_execute_messages = []

if "plan_execute_steps" not in st.session_state:
    st.session_state.plan_execute_steps = []

if "plan_execute_results" not in st.session_state:
    st.session_state.plan_execute_results = []

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–
@st.cache_resource
def get_agent():
    return PlanExecuteAgent()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
with st.sidebar:
    st.header("Plan and Executeå‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
    st.divider()
    st.subheader("ä½¿ç”¨å¯èƒ½ãªè³ªå•ä¾‹:")
    st.markdown("""
    - å—æ³¨ãƒ‡ãƒ¼ã‚¿å–è¾¼ãƒãƒƒãƒã¨å—æ³¨ç¢ºå®šãƒãƒƒãƒã®é•ã„ã‚’æ•™ãˆã¦ãã ã•ã„
    - ç™ºé€ãƒ©ãƒ™ãƒ«ç”Ÿæˆãƒãƒƒãƒã¨ç™ºé€ãƒ‡ãƒ¼ã‚¿ä½œæˆãƒãƒƒãƒã®é–¢ä¿‚ã«ã¤ã„ã¦
    - åœ¨åº«ç®¡ç†ç”»é¢ã®ä¸»ãªæ©Ÿèƒ½ã‚’èª¬æ˜ã—ã¦ãã ã•ã„
    - åœ¨åº«è‡ªå‹•ç™ºæ³¨ãƒãƒƒãƒã®å‡¦ç†å†…å®¹ã‚’è¦ç´„ã—ã¦ãã ã•ã„
    """)

    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    model = st.selectbox(
        "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
        ["gpt-4.1-nano"], 
        index=0
    )
    
    # æ¸©åº¦è¨­å®š
    temperature = st.slider(
        "å¿œç­”ã®å¤šæ§˜æ€§ (temperature)",
        min_value=0.0,
        max_value=1.0,
        value=0.0,
        step=0.1,
        help="0ã«è¿‘ã„ã»ã©æ±ºå®šçš„ãªå›ç­”ã€1ã«è¿‘ã„ã»ã©å‰µé€ çš„ãªå›ç­”ã«ãªã‚Šã¾ã™"
    )
    
# ã‚¿ãƒ–ã®ä½œæˆ
tab1, tab2 = st.tabs(["ãƒãƒ£ãƒƒãƒˆ", "å®Ÿè¡Œè¨ˆç”»"])

with tab1:
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    for message in st.session_state.plan_execute_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
    user_input = st.chat_input("è¨­è¨ˆæ›¸ã«é–¢ã™ã‚‹è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...")

    if user_input:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
        st.session_state.plan_execute_messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # å‡¦ç†ä¸­ã®è¡¨ç¤º
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            message_placeholder.markdown("è¨ˆç”»ã‚’ç«‹æ¡ˆãƒ»å®Ÿè¡Œä¸­ã§ã™...")

            processing_results = {
                    "user_query": user_input,
                    "final_response": None,
                }
            
            try:
                # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–ã¨ãƒ¢ãƒ‡ãƒ«è¨­å®š
                agent = get_agent()
                agent.model_name = model
                agent.temperature = temperature
                
                # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè¡Œ
                with st.status("å‡¦ç†ä¸­...", expanded=False) as status:
                    status.update(label="è¨ˆç”»ã‚’ç«‹æ¡ˆä¸­...", state="running")
                    # åˆæœŸçŠ¶æ…‹ã®ä½œæˆ
                    initial_state = AgentState(query=user_input, last_substep="", last_plan_description="")
                    agent_graph = build_agent_graph()
                    endflg = False
                    
                    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã‚’ä½œæˆ
                    status_placeholder = st.empty()
                    status_messages = []
                    
                    # ã‚°ãƒ©ãƒ•ã®å®Ÿè¡Œ
                    for chunk in agent_graph.stream(initial_state, stream_mode="values", subgraphs=True):
                        
                        node_name = chunk[1]['last_substep']
                        last_plan_description = chunk[1]['last_plan_description']
                        
                        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
                        if node_name == "search":
                            status.update(label="å¿…è¦ãªæƒ…å ±ã‚’åé›†ä¸­...", state="running")
                            status_messages.append("> å¿…è¦ãªæƒ…å ±ã‚’åé›†ä¸­...")
                        elif node_name == "analyze":
                            status.update(label="æƒ…å ±ã®åˆ†æä¸­...", state="running")
                            status_messages.append("> æƒ…å ±ã®åˆ†æä¸­...")
                        elif node_name == "synthesize":
                            status.update(label="æƒ…å ±ã®æ•´ç†ä¸­...", state="running")
                            status_messages.append("> æƒ…å ±ã®æ•´ç†ä¸­...")
                        elif node_name == "unknown":
                            status.update(label="ã‚¨ãƒ©ãƒ¼ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸã€‚", state="running")
                            status_messages.append("> ã‚¨ãƒ©ãƒ¼ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸã€‚")
                        elif node_name == "plan":
                            status.update(label="è¨ˆç”»ã‚’ç«‹æ¡ˆä¸­...", state="running")
                            if last_plan_description != "":
                                status_messages.append("> è¨ˆç”»ã‚’ç«‹æ¡ˆå®Œäº†")
                                status_messages.append(f"> è¨ˆç”»: {last_plan_description}")
                        elif node_name == "revise":
                            status.update(label="å†è¨ˆç”»ä¸­...", state="running")
                            status_messages.append("> å†è¨ˆç”»ä¸­...")
                        elif node_name == "assessment":
                            status.update(label="åé›†ã—ãŸæƒ…å ±ã®è©•ä¾¡ä¸­...", state="running")
                            status_messages.append("> åé›†ã—ãŸæƒ…å ±ã‚’è©•ä¾¡ä¸­...")
                        elif node_name == "generate_answer":
                            status.update(label="æœ€çµ‚å›ç­”ã®ç”Ÿæˆä¸­...", state="running")
                            status_messages.append("> æœ€çµ‚å›ç­”ã®ç”Ÿæˆä¸­...")
                            endflg = True
                        elif node_name == "":
                            status.update(label="å‘¼ã³å‡ºã—ä¸­...", state="running")
                        
                        # HTMLã‚’ä½¿ã£ã¦è¡Œé–“ã‚’åˆ¶å¾¡ã—ã€è“„ç©ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
                        html_content = "<div style='line-height: 1.2; margin-bottom: 0.5rem;'>"
                        html_content += "<br>".join(status_messages)
                        html_content += "</div>"
                        status_placeholder.markdown(html_content, unsafe_allow_html=True)
                        
                        if endflg and chunk[1]['final_answer'] is not None:
                            processing_results["final_response"] = chunk[1]['final_answer']
                            status.update(label="å‡¦ç†å®Œäº†", state="complete")
                        
                    message_placeholder.markdown(processing_results["final_response"])
                    
            
            except Exception as e:
                error_message = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                message_placeholder.markdown(error_message)
                st.error(error_message)
                import traceback
                st.error(traceback.format_exc())

with tab2:
    st.header("Plan and Executeã‚¢ãƒ—ãƒ­ãƒ¼ãƒ")
    
    # æœ€æ–°ã®è¨ˆç”»ã‚’è¡¨ç¤º
    if st.session_state.plan_execute_steps:
        st.write("### å®Ÿè¡Œè¨ˆç”»")
        
        # å„ã‚¹ãƒ†ãƒƒãƒ—ã®è©³ç´°ãªèª¬æ˜
        st.write("### è¨ˆç”»ã‚¹ãƒ†ãƒƒãƒ—ã®è©³ç´°")
        for step in st.session_state.plan_execute_steps:
            st.write(f"**ã‚¹ãƒ†ãƒƒãƒ— {step['step_number']}**: {step['description']}")
            st.write(f"ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—: `{step['action_type']}`")
            st.divider()
        
        # å®Ÿè¡ŒçµæœãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯è¡¨ç¤º
        if st.session_state.plan_execute_results:
            st.write("### å®Ÿè¡Œçµæœã®è©³ç´°")
            for result in st.session_state.plan_execute_results:
                success_emoji = "âœ…" if result["success"] else "âŒ"
                step = result["step"]
                st.markdown(f"{success_emoji} **ã‚¹ãƒ†ãƒƒãƒ— {step['step_number']}**: {step['description']} ({step['action_type']})")
                
                # æ¤œç´¢ã‚¹ãƒ†ãƒƒãƒ—ã®å ´åˆã€ç”Ÿæˆã•ã‚ŒãŸæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è¡¨ç¤º
                if step['action_type'] == 'search' and 'search_queries' in result:
                    st.markdown("**ç”Ÿæˆã•ã‚ŒãŸæ¤œç´¢ã‚¯ã‚¨ãƒª:**")
                    for q_idx, query in enumerate(result['search_queries']):
                        st.markdown(f"- ã‚¯ã‚¨ãƒª {q_idx+1}: `{query}`")
    else:
        st.info("è³ªå•ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€ã“ã“ã«å®Ÿè¡Œè¨ˆç”»ã¨çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

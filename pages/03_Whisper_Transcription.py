import os
import sys
import tempfile
import time
import streamlit as st
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import japanize_matplotlib
import logging  # ãƒ­ã‚°å‡ºåŠ›ç”¨

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ ã—ã¦ã€servicesãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.append(parent_dir)

# éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from services.whisper_transcription import WhisperTranscriptionService

# ãƒ­ã‚°è¨­å®š
log_dir = os.path.join(os.path.dirname(__file__), '..', 'logs')
os.makedirs(log_dir, exist_ok=True)
log_file = os.path.join(log_dir, 'whisper_transcription.log')
logging.basicConfig(
    filename=log_file,
    level=logging.ERROR,
    format='%(asctime)s [%(levelname)s] %(message)s',
    encoding='utf-8'
)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Faster-Whisper éŸ³å£°æ–‡å­—èµ·ã“ã—",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
    if 'audio_file' not in st.session_state:
        st.session_state.audio_file = None
    if 'transcription_result' not in st.session_state:
        st.session_state.transcription_result = None
    if 'process_status' not in st.session_state:
        st.session_state.process_status = None
    if 'segments' not in st.session_state:
        st.session_state.segments = []
    if 'output_format' not in st.session_state:
        st.session_state.output_format = "text"
    if 'language' not in st.session_state:
        st.session_state.language = ""
    if 'processing_time' not in st.session_state:
        st.session_state.processing_time = {}
    if 'confidence_score' not in st.session_state:
        st.session_state.confidence_score = 0.0
    if 'output_file' not in st.session_state:
        st.session_state.output_file = ""
    # è©±è€…åˆ†é›¢é–¢é€£ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°
    if 'enable_diarization' not in st.session_state:
        st.session_state.enable_diarization = True
    if 'speaker_count' not in st.session_state:
        st.session_state.speaker_count = 0
    if 'speaker_segments' not in st.session_state:
        st.session_state.speaker_segments = []
    # æ–‡å­—èµ·ã“ã—è¦ç´„é–¢é€£ã®çŠ¶æ…‹å¤‰æ•°
    if 'summary_result' not in st.session_state:
        st.session_state.summary_result = None
    if 'summary_status' not in st.session_state:
        st.session_state.summary_status = None
    if 'summary_processing_time' not in st.session_state:
        st.session_state.summary_processing_time = 0.0
    if 'include_speaker_info' not in st.session_state:
        st.session_state.include_speaker_info = True

def sidebar_content():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¡¨ç¤º"""
    with st.sidebar:
        st.header("è¨­å®š")
        
        st.subheader("ãƒ¢ãƒ‡ãƒ«è¨­å®š")
        model_info = st.expander("ãƒ¢ãƒ‡ãƒ«æƒ…å ±", expanded=False)
        with model_info:
            st.write("**ãƒ¢ãƒ‡ãƒ«**: Faster-Whisper large-v3-turbo")
            st.write("**æ¦‚è¦**: OpenAIã®Whisperãƒ¢ãƒ‡ãƒ«ã®æœ€é©åŒ–ç‰ˆã§ã€æœ€é«˜ç²¾åº¦ã‚’æä¾›ã—ã¾ã™ã€‚")
            st.write("**ã‚µã‚¤ã‚º**: ç´„3GB")
            st.write("**ã‚µãƒãƒ¼ãƒˆè¨€èª**: 99è¨€èª")
            
        st.subheader("è¨€èªè¨­å®š")
        language_options = {
            "": "è‡ªå‹•æ¤œå‡º",
            "ja": "æ—¥æœ¬èª",
            "en": "è‹±èª",
            "zh": "ä¸­å›½èª",
            "ko": "éŸ“å›½èª",
            "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª",
            "de": "ãƒ‰ã‚¤ãƒ„èª",
            "es": "ã‚¹ãƒšã‚¤ãƒ³èª",
            "it": "ã‚¤ã‚¿ãƒªã‚¢èª",
            "ru": "ãƒ­ã‚·ã‚¢èª"
        }
        
        selected_language = st.selectbox(
            "è¨€èªã‚’é¸æŠï¼ˆç©ºç™½ã®å ´åˆã¯è‡ªå‹•æ¤œå‡ºï¼‰",
            options=list(language_options.keys()),
            format_func=lambda x: language_options[x],
            index=0
        )
        st.session_state.language = selected_language
        
        st.subheader("å‡ºåŠ›å½¢å¼")
        format_options = {
            "vtt": "Webå­—å¹• (VTT)",
            "text": "ãƒ†ã‚­ã‚¹ãƒˆ (TXT)",
            "srt": "å­—å¹• (SRT)",
            "json": "æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ (JSON)"
        }
        
        selected_format = st.selectbox(
            "å‡ºåŠ›å½¢å¼ã‚’é¸æŠ",
            options=list(format_options.keys()),
            format_func=lambda x: format_options[x],
            index=0
        )
        st.session_state.output_format = selected_format
        st.subheader("è©±è€…åˆ†é›¢è¨­å®š")
        st.session_state.enable_diarization = st.toggle(
            "è©±è€…åˆ†é›¢æ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã™ã‚‹", 
            value=True, 
            help="éŸ³å£°å†…ã®è¤‡æ•°ã®è©±è€…ã‚’è­˜åˆ¥ã—ã€å„ç™ºè¨€ã«è©±è€…ãƒ©ãƒ™ãƒ«ã‚’ä»˜ã‘ã¾ã™"
        )
        
        st.subheader("è©³ç´°è¨­å®š")
        with st.expander("è©³ç´°è¨­å®š", expanded=False):
            st.write("**å‹•ä½œç’°å¢ƒ**:")
            use_gpu = torch.cuda.is_available()
            st.write(f"GPU: {'âœ… åˆ©ç”¨å¯èƒ½' if use_gpu else 'âŒ åˆ©ç”¨ä¸å¯'}")
            st.write(f"ãƒ‡ãƒã‚¤ã‚¹: {'CUDA' if use_gpu else 'CPU'}")
            
            if use_gpu:
                st.write(f"GPUå: {torch.cuda.get_device_name(0)}")
            
            st.divider()
            st.write("**ãƒ•ã‚¡ã‚¤ãƒ«åˆ¶é™**:")
            st.write("æœ€å¤§ã‚µã‚¤ã‚º: 500MB")
            st.write("å¯¾å¿œå½¢å¼: WAV, MP3, FLAC, OGG")
        
        # è‘—è€…æƒ…å ±
        st.sidebar.divider()
        st.sidebar.caption("Faster-Whisper Transcription Service")
        st.sidebar.caption("Developed with â¤ï¸ using Streamlit & Faster-Whisper")

def render_upload_tab():
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¿ãƒ–ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¡¨ç¤º"""
    st.header("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader(
        "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (WAV, MP3, FLAC, M4A, OGG)",
        type=["wav", "mp3", "flac", "m4a", "ogg"]
    )
    
    if uploaded_file is not None:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        temp_dir = tempfile.mkdtemp()
        temp_path = os.path.join(temp_dir, uploaded_file.name)
        
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        st.session_state.audio_file = temp_path
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®è¡¨ç¤º
        file_size = os.path.getsize(temp_path) / (1024 * 1024)  # MBã«å¤‰æ›
        
        st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ: {uploaded_file.name}")
        
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±")
            st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«å**: {uploaded_file.name}")
            st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: {file_size:.2f} MB")
            st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼**: {os.path.splitext(uploaded_file.name)[1].upper()[1:]}")
            
            # éŸ³å£°ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®è¡¨ç¤º
            st.audio(uploaded_file, format=f"audio/{os.path.splitext(uploaded_file.name)[1][1:]}")
        with col2:
            st.subheader("ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š")
            st.write(f"**è¨€èª**: {st.session_state.language if st.session_state.language else 'è‡ªå‹•æ¤œå‡º'}")
            st.write(f"**å‡ºåŠ›å½¢å¼**: {st.session_state.output_format.upper()}")
            st.write(f"**è©±è€…åˆ†é›¢**: {'æœ‰åŠ¹' if st.session_state.enable_diarization else 'ç„¡åŠ¹'}")
            
            # å®Ÿè¡Œãƒœã‚¿ãƒ³
            start_button = st.button("æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹", type="primary", use_container_width=True)
            if start_button:
                with st.spinner("æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œä¸­..."):
                    try:
                        # æ–‡å­—èµ·ã“ã—ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–
                        service = WhisperTranscriptionService()
                        # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
                        start_time = time.time()
                        result = service.transcribe(
                            audio_file=st.session_state.audio_file,
                            language=st.session_state.language,
                            format_type=st.session_state.output_format,
                            enable_diarization=st.session_state.enable_diarization
                        )
                        end_time = time.time()
                        
                        # LangGraphã®çµæœã¯è¾æ›¸ã®ã‚ˆã†ãªå½¢å¼ã§ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹
                        # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                        # æ–°ã—ã„å½¢å¼ï¼ˆè¾æ›¸å½¢å¼ã§ã®ã‚¢ã‚¯ã‚»ã‚¹ï¼‰                    
                        st.session_state.transcription_result = result["transcript"]
                        st.session_state.process_status = result["status"]
                        st.session_state.segments = result["segments"]
                        st.session_state.processing_time = result["processing_time"]
                        st.session_state.confidence_score = result["confidence_score"]
                        st.session_state.output_file = result["output_file"]
                        
                        # è©±è€…åˆ†é›¢æƒ…å ±ã®ä¿å­˜
                        if st.session_state.enable_diarization:
                            st.session_state.speaker_count = result.get("speaker_count", 0)
                            st.session_state.speaker_segments = result.get("speaker_segments", [])
                        
                        # æ–‡å­—èµ·ã“ã—å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
                        processing_time_str = format_time(result["processing_time"].get("total", 0))
                        confidence_percentage = int(result["confidence_score"] * 100)
                        st.info(f"ğŸ‰ æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸï¼çµæœã‚¿ãƒ–ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\nå‡¦ç†æ™‚é–“: {processing_time_str} | ä¿¡é ¼åº¦: {confidence_percentage}%")
                    except Exception as e:
                        logging.error(f"æ–‡å­—èµ·ã“ã—å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                        st.error("æ–‡å­—èµ·ã“ã—å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°ã¯ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚")
                    

def format_time(seconds):
    """ç§’æ•°ã‚’æ™‚é–“å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if seconds < 60:
        return f"{seconds:.2f}ç§’"
    elif seconds < 3600:
        minutes = int(seconds / 60)
        seconds = seconds % 60
        return f"{minutes}åˆ† {seconds:.2f}ç§’"
    else:
        hours = int(seconds / 3600)
        seconds %= 3600
        minutes = int(seconds / 60)
        seconds %= 60
        return f"{hours}æ™‚é–“ {minutes}åˆ† {seconds:.2f}ç§’"

def get_confidence_class(confidence):
    """ä¿¡é ¼åº¦ã«åŸºã¥ã„ãŸCSSã‚¯ãƒ©ã‚¹ã‚’è¿”ã™"""
    if confidence >= 0.8:
        return "confidence-high"
    elif confidence >= 0.6:
        return "confidence-med"
    else:
        return "confidence-low"

def render_result_tab():
    """çµæœã‚¿ãƒ–ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¡¨ç¤º"""
    if st.session_state.transcription_result is None:
        st.info("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
        return
    
    st.header("æ–‡å­—èµ·ã“ã—çµæœ")
    
    # å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®è¡¨ç¤º
    if st.session_state.process_status == "completed":
        st.success("æ–‡å­—èµ·ã“ã—ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
    elif st.session_state.process_status == "error":
        st.error("æ–‡å­—èµ·ã“ã—å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
      # å‡¦ç†æ™‚é–“ã¨ä¿¡é ¼åº¦ã®ã‚µãƒãƒªãƒ¼
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç·å‡¦ç†æ™‚é–“", format_time(st.session_state.processing_time.get("total", 0)))
    
    with col2:
        confidence_percentage = int(st.session_state.confidence_score * 100)
        st.metric("ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢", f"{confidence_percentage}%")
    
    with col3:
        if st.session_state.language:
            language_name = {
                "ja": "æ—¥æœ¬èª",
                "en": "è‹±èª",
                "zh": "ä¸­å›½èª",
                "ko": "éŸ“å›½èª",
                "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª",
                "de": "ãƒ‰ã‚¤ãƒ„èª",
                "es": "ã‚¹ãƒšã‚¤ãƒ³èª",
                "it": "ã‚¤ã‚¿ãƒªã‚¢èª",
                "ru": "ãƒ­ã‚·ã‚¢èª"
            }.get(st.session_state.language, st.session_state.language)
        else:
            language_name = "è‡ªå‹•æ¤œå‡º"
        st.metric("æ¤œå‡ºè¨€èª", language_name)
    
    with col4:
        if st.session_state.enable_diarization:
            st.metric("æ¤œå‡ºè©±è€…æ•°", str(st.session_state.speaker_count))
    
    # å‡¦ç†æ™‚é–“ã®è©³ç´°ã‚°ãƒ©ãƒ•
    if st.session_state.processing_time:
        with st.expander("å‡¦ç†æ™‚é–“ã®è©³ç´°", expanded=False):
            processing_time = {k: v for k, v in st.session_state.processing_time.items() if k != "total"}
            
            fig, ax = plt.subplots(figsize=(10, 5))
            steps = list(processing_time.keys())
            times = list(processing_time.values())
            
            ax.barh(steps, times, color='green')
            ax.set_xlabel('å‡¦ç†æ™‚é–“ (ç§’)')
            ax.set_title('å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®å®Ÿè¡Œæ™‚é–“')
            ax.grid(axis='x', linestyle='--', alpha=0.7)
            
            st.pyplot(fig)    # æ–‡å­—èµ·ã“ã—çµæœã®è¡¨ç¤º
    st.subheader("æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ")
    
    with st.container(border=True):
        if st.session_state.enable_diarization and st.session_state.speaker_count > 0:
            # è©±è€…æƒ…å ±ã‚’å«ã‚ãŸè¡¨ç¤ºï¼ˆHTMLå½¢å¼ã§è£…é£¾ï¼‰
            for segment in st.session_state.segments:
                speaker = segment.get("speaker", "ä¸æ˜")
                speaker_class = speaker.replace(" ", "_")  # CSSã‚¯ãƒ©ã‚¹åã«é©ã—ãŸå½¢å¼ã«å¤‰æ›
                
                # æ™‚é–“æƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                start_time = format_time(segment["start"]).replace("ç§’", "")
                
                # HTMLå½¢å¼ã§ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼æƒ…å ±ã¨ç™ºè©±å†…å®¹ã‚’è¡¨ç¤º
                st.markdown(f"""
                <div class="speaker-container speaker-{speaker_class}">
                    <div class="speaker-label speaker-label-{speaker_class}">ã€{speaker}ã€‘ {start_time}</div>
                    <div class="speaker-text">{segment['text']}</div>
                </div>
                """, unsafe_allow_html=True)
        else:
            # é€šå¸¸ã®æ–‡å­—èµ·ã“ã—çµæœ
            st.write(st.session_state.transcription_result)
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
    if st.session_state.output_file and os.path.exists(st.session_state.output_file):
        with open(st.session_state.output_file, "rb") as file:
            file_extension = os.path.splitext(st.session_state.output_file)[1]
            file_name = os.path.basename(st.session_state.output_file)
            
            st.download_button(
                label=f"çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ({file_extension.upper()[1:]}å½¢å¼)",
                data=file,
                file_name=file_name,
                mime=f"text/{file_extension[1:]}"
            )
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè©³ç´°ã®è¡¨ç¤º
    if st.session_state.segments:
        st.subheader("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè©³ç´°")
        
        with st.expander("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’è¡¨ç¤º", expanded=False):            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’DataFrameã«å¤‰æ›
            segments_data = []
            for segment in st.session_state.segments:
                segments_data.append({
                    "é–‹å§‹æ™‚é–“": segment["start"],
                    "çµ‚äº†æ™‚é–“": segment["end"],
                    "ãƒ†ã‚­ã‚¹ãƒˆ": segment["text"],
                    "è©±è€…": segment.get("speaker", "ä¸æ˜"),
                    "ä¿¡é ¼åº¦": segment.get("probability", 0)
                })
            
            df = pd.DataFrame(segments_data)
            
            # æ™‚é–“ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›
            df["é–‹å§‹æ™‚é–“"] = df["é–‹å§‹æ™‚é–“"].apply(lambda x: f"{int(x/60):02d}:{int(x%60):02d}.{int((x%1)*1000):03d}")
            df["çµ‚äº†æ™‚é–“"] = df["çµ‚äº†æ™‚é–“"].apply(lambda x: f"{int(x/60):02d}:{int(x%60):02d}.{int((x%1)*1000):03d}")
            
            # ä¿¡é ¼åº¦ã‚’ç™¾åˆ†ç‡ã«å¤‰æ›
            df["ä¿¡é ¼åº¦"] = df["ä¿¡é ¼åº¦"].apply(lambda x: f"{min(100, max(0, int((1.0 + x/10)*100)))}%")
            
            st.dataframe(
                df,
                hide_index=True,
                column_config={
                    "ãƒ†ã‚­ã‚¹ãƒˆ": st.column_config.TextColumn(width="large")
                },
                height=400
            )
        
        # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ“ãƒ¥ãƒ¼
        with st.expander("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³", expanded=False):            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’è¦–è¦šåŒ–
            max_time = max([segment["end"] for segment in st.session_state.segments])
            
            fig, ax = plt.subplots(figsize=(12, 6))
            
            # è©±è€…ã”ã¨ã«è‰²ã‚’åˆ†ã‘ã‚‹
            speakers = set()
            for segment in st.session_state.segments:
                if "speaker" in segment:
                    speakers.add(segment["speaker"])
                      # è©±è€…ã”ã¨ã®è‰²ã‚’è¨­å®š
            speaker_colors = {}
            # éæ¨å¥¨ã®get_cmapã®ä»£ã‚ã‚Šã«pyplot.get_cmap()ã‚’ä½¿ç”¨
            color_map = plt.get_cmap('tab10', max(10, len(speakers)))
            for i, speaker in enumerate(speakers):
                speaker_colors[speaker] = color_map(i)
            
            for i, segment in enumerate(st.session_state.segments):
                confidence = min(1.0, max(0.0, 1.0 + segment.get("probability", 0) / 10))
                
                # è©±è€…ã«åŸºã¥ã„ã¦è‰²ã‚’é¸æŠ
                if "speaker" in segment and segment["speaker"] in speaker_colors:
                    color = speaker_colors[segment["speaker"]]
                else:
                    color = plt.cm.RdYlGn(confidence)
                
                ax.barh(
                    i, 
                    segment["end"] - segment["start"], 
                    left=segment["start"], 
                    color=color, 
                    alpha=0.7,
                    height=0.5
                )
            
            ax.set_yticks(range(len(st.session_state.segments)))
            ax.set_yticklabels([f"#{i} {segment.get('speaker', '')}" for i, segment in enumerate(st.session_state.segments)])
            ax.set_xlabel("æ™‚é–“ (ç§’)")
            
            # å‡¡ä¾‹ã‚’è¿½åŠ 
            if st.session_state.enable_diarization and speakers:
                legend_elements = [plt.Rectangle((0, 0), 1, 1, color=speaker_colors.get(speaker, 'gray'), alpha=0.7) 
                                  for speaker in speakers]
                ax.legend(legend_elements, speakers, loc="upper right", title="è©±è€…")
                ax.set_title("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ (è‰²ã¯è©±è€…ã‚’è¡¨ã—ã¾ã™)")
            else:
                ax.set_title("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ (è‰²ã¯ä¿¡é ¼åº¦ã‚’è¡¨ã—ã¾ã™)")
                
            ax.grid(axis='x', linestyle='--', alpha=0.5)
            
            st.pyplot(fig)
            
            # è©±è€…åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³
        if st.session_state.enable_diarization and st.session_state.speaker_count > 0:
            with st.expander("è©±è€…åˆ†ææƒ…å ±", expanded=False):
                # å„è©±è€…ã®ç™ºè©±æ™‚é–“ã‚’åˆ†æ
                speaker_times = {}
                for segment in st.session_state.segments:
                    speaker = segment.get("speaker", "ä¸æ˜")
                    duration = segment["end"] - segment["start"]
                    if speaker in speaker_times:
                        speaker_times[speaker] += duration
                    else:
                        speaker_times[speaker] = duration
                
                total_duration = sum(speaker_times.values())
                
                # è©±è€…ã®ç™ºè©±æ™‚é–“ã‚°ãƒ©ãƒ•
                fig, ax = plt.subplots(figsize=(10, 5))
                speakers = list(speaker_times.keys())
                durations = list(speaker_times.values())
                percentages = [d/total_duration*100 for d in durations]
                
                # è‰²ã®è¨­å®š
                colors = plt.cm.tab10(range(len(speakers)))
                
                # æ£’ã‚°ãƒ©ãƒ•
                ax.bar(speakers, durations, color=colors)
                ax.set_ylabel('ç™ºè©±æ™‚é–“ (ç§’)')
                ax.set_title('è©±è€…ã”ã¨ã®ç™ºè©±æ™‚é–“')
                
                # å„ãƒãƒ¼ã®ä¸Šã«å‰²åˆã‚’è¡¨ç¤º
                for i, (d, p) in enumerate(zip(durations, percentages)):
                    ax.annotate(f'{d:.1f}ç§’\n({p:.1f}%)', 
                              xy=(i, d), 
                              xytext=(0, 3),
                              textcoords="offset points", 
                              ha='center', va='bottom')
                
                st.pyplot(fig)
                
                # è©±è€…ã”ã¨ã®ç™ºè©±å›æ•°
                speaker_counts = {}
                for segment in st.session_state.segments:
                    speaker = segment.get("speaker", "ä¸æ˜")
                    if speaker in speaker_counts:
                        speaker_counts[speaker] += 1
                    else:
                        speaker_counts[speaker] = 1
                
                # ç™ºè©±å›æ•°è¡¨ã‚’è¡¨ç¤º
                st.subheader("è©±è€…ã”ã¨ã®ç™ºè©±æƒ…å ±")
                speaker_data = []
                for speaker, count in speaker_counts.items():
                    speaker_data.append({
                        "è©±è€…": speaker,
                        "ç™ºè©±å›æ•°": count,
                        "åˆè¨ˆç™ºè©±æ™‚é–“": f"{speaker_times[speaker]:.2f}ç§’",
                        "ç™ºè©±å‰²åˆ": f"{speaker_times[speaker]/total_duration*100:.1f}%"
                    })
                
                st.dataframe(
                    pd.DataFrame(speaker_data),
                    hide_index=True,
                    use_container_width=True
                )

def render_summary_tab():
    """è¦ç´„ã‚¿ãƒ–ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¡¨ç¤º"""
    st.header("æ–‡å­—èµ·ã“ã—å†…å®¹ã®è¦ç´„")
    
    # æ–‡å­—èµ·ã“ã—çµæœãŒãªã„å ´åˆ
    if st.session_state.transcription_result is None:
        st.info("ã¾ãšéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦æ–‡å­—èµ·ã“ã—ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
        return
      # è¦ç´„ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    with st.expander("è¦ç´„ã‚ªãƒ—ã‚·ãƒ§ãƒ³", expanded=False):
        st.write("è¦ç´„ã®è©³ç´°åº¦ã‚„é•·ã•ã‚’èª¿æ•´ã§ãã¾ã™ã€‚")
        summary_length = st.select_slider(
            "è¦ç´„ã®é•·ã•",
            options=["çŸ­ã‚", "æ¨™æº–", "è©³ç´°"],
            value="æ¨™æº–"
        )
        
        include_speaker_info = st.toggle(
            "è©±è€…æƒ…å ±ã‚’å«ã‚ã‚‹", 
            value=True,
            help="è¦ç´„ã«è©±è€…ï¼ˆSPEAKER_01, SPEAKER_02ãªã©ï¼‰ã®ç™ºè¨€å†…å®¹ã‚’åŒºåˆ¥ã—ã¦å«ã‚ã¾ã™"
        )
          # è¦ç´„ãƒœã‚¿ãƒ³
    if st.button("æ–‡å­—èµ·ã“ã—å†…å®¹ã‚’è¦ç´„", type="primary", use_container_width=True):
        with st.spinner("æ–‡å­—èµ·ã“ã—å†…å®¹ã‚’è¦ç´„ä¸­..."):
            try:
                # WhisperTranscriptionServiceã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
                service = WhisperTranscriptionService()
                
                # ãƒˆã‚°ãƒ«ã®çŠ¶æ…‹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                st.session_state.include_speaker_info = include_speaker_info
                
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã®æº–å‚™ï¼ˆè©±è€…æƒ…å ±ã‚’å«ã‚ã‚‹ã‹ã©ã†ã‹ï¼‰
                segments_for_summary = st.session_state.segments
                if not include_speaker_info:
                    # è©±è€…æƒ…å ±ã‚’å«ã¾ãªã„å ´åˆã¯ã€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰è©±è€…æƒ…å ±ã‚’å‰Šé™¤ã—ãŸã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
                    segments_for_summary = []
                    for segment in st.session_state.segments:
                        segment_copy = segment.copy()
                        if "speaker" in segment_copy:
                            del segment_copy["speaker"]
                        segments_for_summary.append(segment_copy)
                
                # ã‚µãƒ¼ãƒ“ã‚¹ã®è¦ç´„ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—
                result = service.summarize_transcription(
                    text=st.session_state.transcription_result,
                    language=st.session_state.language,
                    segments=segments_for_summary  # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ï¼ˆæ™‚é–“æƒ…å ±ã¨è©±è€…æƒ…å ±ã‚’å«ã‚€/å«ã¾ãªã„ï¼‰ã‚’æ¸¡ã™
                )
                
                # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                st.session_state.summary_result = result["summary"]
                st.session_state.summary_status = result["status"]
                st.session_state.summary_processing_time = result.get("processing_time", 0)
                
                # è¦ç´„å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
                if result["status"] == "completed":
                    st.success(f"è¦ç´„ãŒå®Œäº†ã—ã¾ã—ãŸï¼ å‡¦ç†æ™‚é–“: {format_time(result.get('processing_time', 0))}")
                else:
                    st.error(f"è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {result.get('error_message', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
            except Exception as e:
                logging.error(f"è¦ç´„å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                st.error("è¦ç´„å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°ã¯ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚")
    # è¦ç´„çµæœã®è¡¨ç¤º
    if st.session_state.summary_result:
        st.subheader("è¦ç´„çµæœ")
        
        with st.container(border=True):
            st.write(st.session_state.summary_result)
        
        # å‡¦ç†æ™‚é–“ã®è¡¨ç¤º
        st.caption(f"å‡¦ç†æ™‚é–“: {format_time(st.session_state.summary_processing_time)}")
        
        # è¦ç´„çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        # ç¾åœ¨ã®æ—¥æ™‚ã‚’å–å¾—ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã«å«ã‚ã‚‹
        from datetime import datetime
        current_datetime = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ãƒ™ãƒ¼ã‚¹ã«ã™ã‚‹ï¼ˆsession_stateã«audio_fileãŒã‚ã‚‹å ´åˆï¼‰
        base_filename = "summary"
        if st.session_state.audio_file:
            base_filename = os.path.splitext(os.path.basename(st.session_state.audio_file))[0] + "_summary"
        
        summary_filename = f"{base_filename}_{current_datetime}.txt"
        
        st.download_button(
            label="è¦ç´„çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (TXTå½¢å¼)",
            data=st.session_state.summary_result,
            file_name=summary_filename,
            mime="text/plain",
            key="download_summary"
        )
        
        # å…ƒã®æ–‡å­—èµ·ã“ã—ã¨ã®æ¯”è¼ƒ
        with st.expander("å…ƒã®æ–‡å­—èµ·ã“ã—å†…å®¹ã¨æ¯”è¼ƒ", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("è¦ç´„")
                st.write(st.session_state.summary_result)
            
            with col2:
                st.subheader("å…ƒã®æ–‡å­—èµ·ã“ã—")
                st.write(st.session_state.transcription_result)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    init_session_state()
    
    # ã‚«ã‚¹ã‚¿ãƒ CSS
    st.markdown("""
    <style>
        .speaker-container {
            padding: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
            border-left: 5px solid #4e8cff;
        }
        .speaker-label {
            font-weight: bold;
            color: #4e8cff;
            margin-bottom: 5px;
        }
        .speaker-text {
            margin-left: 10px;
        }
        .speaker-SPEAKER_00 { border-left-color: #FF4E4E; }
        .speaker-SPEAKER_01 { border-left-color: #4E8CFF; }
        .speaker-SPEAKER_02 { border-left-color: #4EFF8C; }
        .speaker-SPEAKER_03 { border-left-color: #FF8C4E; }
        .speaker-SPEAKER_04 { border-left-color: #8C4EFF; }
        .speaker-SPEAKER_05 { border-left-color: #FFFF4E; }
        .speaker-label-SPEAKER_00 { color: #FF4E4E; }
        .speaker-label-SPEAKER_01 { color: #4E8CFF; }
        .speaker-label-SPEAKER_02 { color: #4EFF8C; }
        .speaker-label-SPEAKER_03 { color: #FF8C4E; }
        .speaker-label-SPEAKER_04 { color: #8C4EFF; }
        .speaker-label-SPEAKER_05 { color: #FFFF4E; }
    </style>
    """, unsafe_allow_html=True)
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¡¨ç¤º
    sidebar_content()
    
    # ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
    st.title("ğŸ¤ Faster-Whisper éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚µãƒ¼ãƒ“ã‚¹")
    st.write("""
    é«˜ç²¾åº¦ãªéŸ³å£°æ–‡å­—èµ·ã“ã—ã‚µãƒ¼ãƒ“ã‚¹ã§ã™ã€‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€
    Faster-Whisperãƒ¢ãƒ‡ãƒ«(large-v3-turbo)ã‚’ä½¿ç”¨ã—ã¦æ–‡å­—èµ·ã“ã—ã‚’è¡Œã„ã¾ã™ã€‚
    è¤‡æ•°ã®è¨€èªã¨å‡ºåŠ›å½¢å¼ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚
    """)
      # ã‚¿ãƒ–ã®ä½œæˆ
    tab1, tab2, tab3 = st.tabs(["ğŸ“¤ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ", "ğŸ“‹ æ–‡å­—èµ·ã“ã—è¦ç´„"])
    
    with tab1:
        render_upload_tab()
    
    with tab2:
        render_result_tab()
    
    with tab3:
        render_summary_tab()

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
if __name__ == "__main__":
    import torch
    main()